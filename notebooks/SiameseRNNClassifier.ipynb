{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8900d5dc-51eb-4ef5-9878-13baac7d550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/envs/dragon/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "74f2c8f8-d9cc-4ffd-b462-963eff249c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_message_activity(hw, target=1, max_interval=10):\n",
    "    noise_strength = np.random.randint(4, size=1)\n",
    "    x = np.array(list(range(0, hw)))\n",
    "    y = np.cos(x)  + 1 + np.random.randint(4, size=len(x))#*noise_strength\n",
    "    step = np.random.choice([0, 0.1, 0.15, 0.25, 0.3, 0.4, 0.5])\n",
    "    sv = int(step * hw)\n",
    "    k = int(hw / 32)\n",
    "    k = k if k else 1\n",
    "    y[sv:] += x[sv:]/1.8/k + abs(y[sv])\n",
    "    y *= max_interval / 10\n",
    "    if target == 0:\n",
    "        return y[::-1] / 3\n",
    "    return y / 3\n",
    "\n",
    "\n",
    "def generate_message_activity_plane(hw, target=1, max_interval=10):\n",
    "    noise_strength = 0.5\n",
    "    x = np.array(list(range(0, hw)))\n",
    "    h = 1 + np.random.randint(1, size=1) if target == 0 else 5+np.random.randint(4, size=1)\n",
    "    t = 0.4 if target == 0 else 1+np.random.randint(2, size=1)\n",
    "    y = t * np.cos(x) + h + np.random.randint(3, size=len(x))*noise_strength\n",
    "    y *= max_interval / 10\n",
    "    return y\n",
    "\n",
    "\n",
    "def generate_by(hw, plane, pos, max_interval):\n",
    "    if plane:\n",
    "        return generate_message_activity_plane(hw, pos, max_interval)\n",
    "    else:\n",
    "        return generate_message_activity(hw, pos, max_interval)\n",
    "\n",
    "\n",
    "def gen_historic_data(hw = 40, c = 7, pos_size = 0, last_pos= 0, max_interval=13):\n",
    "    hist = []\n",
    "    last = None\n",
    "    target = None\n",
    "    \n",
    "    ps = int(np.round(c * pos_size))\n",
    "    '''\n",
    "    for _ in range(ps):\n",
    "        hist.append(generate_by(hw, np.random.choice([0, 1]), 1, max_interval))\n",
    "    for _ in range(c - ps):\n",
    "        hist.append(generate_by(hw, np.random.choice([0, 1]), 0, max_interval))\n",
    "#    hist = np.array(hist).mean(axis=0)\n",
    "    '''\n",
    "    if pos_size:\n",
    "        if last_pos:\n",
    "            last = generate_by(365-hw, np.random.choice([0, 1]), 1, max_interval)\n",
    "            target = 1\n",
    "        else:\n",
    "            last = generate_by(365-hw, np.random.choice([0, 1]), 0, max_interval)\n",
    "            target = 0\n",
    "    else:\n",
    "        plane = np.random.choice([0, 1])\n",
    "        if last_pos:\n",
    "            last = generate_by(365-hw, plane, 1, max_interval)\n",
    "            target = 1\n",
    "        else:\n",
    "            last = generate_by(365-hw, plane, 0, max_interval)\n",
    "            if not plane:\n",
    "                target = 1\n",
    "            else:\n",
    "                target = 0\n",
    "    activity_series = generate_by(hw, np.random.choice([0, 1]), pos_size, max_interval)\n",
    "    \n",
    "    \n",
    "    # padding\n",
    "    activity_series = np.pad(activity_series, (365 - len(activity_series)%365, 0))\n",
    "    last = np.pad(last, (365 - len(last)%365, 0))\n",
    "    \n",
    "    return activity_series, last, target\n",
    "\n",
    "\n",
    "def gen_dataset(hw, c, size, max_interval):\n",
    "    activity = []\n",
    "    target = []\n",
    "    last_a = []\n",
    "    \n",
    "    for _ in range(size):\n",
    "        pos_size = np.random.choice([0, 1])\n",
    "        last_pos = np.random.choice([0, 1])\n",
    "        hw = np.random.randint(10, 320)\n",
    "        act, last, targ = gen_historic_data(hw=hw, c=c, pos_size=pos_size, last_pos=last_pos, max_interval=max_interval)\n",
    "        activity.append(np.round(act))\n",
    "        last_a.append(np.round(last))\n",
    "        target.append(targ)\n",
    "        \n",
    "    return activity, last_a, target\n",
    "        \n",
    "\n",
    "def gen_worker_df(max_range):\n",
    "    df_dict = {}\n",
    "    for k in max_range:\n",
    "        pos_size = np.random.choice([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "        last_pos = np.random.choice([0, 1])\n",
    "        df_dict[k] = gen_historic_data(hw=40, c=11, pos_size=pos_size, last_pos=last_pos, max_interval=max_range[k])[0].astype(int)\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "54eab6bb-c124-4d88-b577-97f8553019c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range = {\"sent_messages_count\": 10,\n",
    "\"received_messages_count\": 10, \n",
    "\"recipient_counts\": 10, \n",
    "\"bcc_count\": 10, \n",
    "\"cc_count\": 10, \n",
    "\"read_messages_later_than\": 10, \n",
    "\"days_between_received_and_read\":5, \n",
    "\"replied_messages_count\": 10, \n",
    "\"sent_characters_count\": 5400, \n",
    "\"messages_outside_working_hours\": 10, \n",
    "#\"received_to_sent_ratio\": 1, \n",
    "\"messages_with_question_and_no_reply\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "27c3d67d-6a12-4caa-98d8-5bfefafe75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_up = {\"sent_messages_count\": 1,\n",
    "\"received_messages_count\": 1, \n",
    "\"recipient_counts\": 1, \n",
    "\"bcc_count\": 1, \n",
    "\"cc_count\": 1, \n",
    "\"read_messages_later_than\": 0, \n",
    "\"days_between_received_and_read\":0, \n",
    "\"replied_messages_count\": 1, \n",
    "\"sent_characters_count\": 1, \n",
    "\"messages_outside_working_hours\": 0, \n",
    "#\"received_to_sent_ratio\": 1, \n",
    "\"messages_with_question_and_no_reply\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "6cea75b5-3dbf-4975-8c7f-2c26afb4dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities, last, targets = gen_dataset(40, 11, 5000, 10)\n",
    "v_activities, v_last, v_targets = gen_dataset(40, 11, 1000, 5400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5de08-8aff-4373-9126-cb66acefa48b",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "activities_scaled = scaler.fit_transform(activities)\n",
    "v_activities_scaled = scaler.transform(v_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "b670619f-d0a3-42d3-8d71-3b2aa1a1c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(sample_mat, interval_max):\n",
    "    scaled_mat = sample_mat / interval_max\n",
    "    return scaled_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "f781db6e-2b8a-4af5-ae46-69f8bcd09bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_max(worker, max_range):\n",
    "    wk_dict = worker.to_dict(orient=\"list\")\n",
    "    scaled_worker = {}\n",
    "    for k in max_range:\n",
    "        scaled_worker[k] = scale(np.array(wk_dict[k]), max_range[k])\n",
    "    return scaled_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "4bdff928-1fcd-4072-a4d2-555a18fc1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_max(model, scaled_worker, type_up):\n",
    "    proba = 0\n",
    "    for k in type_up:\n",
    "        x = torch.tensor(scaled_worker[k]).unsqueeze(0).unsqueeze(2).float()\n",
    "        pred = model(x).item()\n",
    "        if not type_up[k]:\n",
    "            pred = 1 - pred\n",
    "        proba += pred\n",
    "    return 1 - proba  / len(type_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "a69cc575-cd25-43b2-9f05-9f7120f29beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(targets) / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "530e3c43-6e2b-4688-b32a-8ceaf647253a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(v_targets) / len(v_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "9b24caa1-18a8-45b6-a14b-19000fe4644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_scaled = scale(np.array(activities), 10)\n",
    "v_activities_scaled = scale(np.array(v_activities), 5400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "8f310c88-d267-4dcf-b6a2-0ad57b55d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scaled = scale(np.array(last), 10)\n",
    "v_last_scaled = scale(np.array(v_last), 5400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b9538-cebf-45d3-8a56-b6c873297005",
   "metadata": {},
   "source": [
    "import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "# And now to load...\n",
    "scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "b076785c-7567-4e7c-b6a3-3d9f1285740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_t = torch.tensor(activities_scaled).float()\n",
    "v_activities_t = torch.tensor(v_activities_scaled).float()\n",
    "\n",
    "last_t = torch.tensor(last_scaled).float()\n",
    "v_last_t = torch.tensor(v_last_scaled).float()\n",
    "\n",
    "targets_t = torch.tensor(targets).float()\n",
    "v_targets_t = torch.tensor(v_targets).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "44245228-24e1-4929-8dea-cbc81681583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(activities_t, last_t, targets_t)\n",
    "train_dl = DataLoader(train_dataset, 32, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa3ee0-2962-4298-a143-2a2bae064c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "62e92d9b-82f4-43e6-9b0c-c14fdbcc362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(v_activities_t, v_last_t, v_targets_t)\n",
    "val_dl = DataLoader(val_dataset, 32, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "e242cb09-95ae-42a7-b60d-6331a0e3233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    return (output.argmax(dim=1) == target).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "0b554e30-efbd-4e68-85be-d88a589115cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "0e6629c0-986e-454c-bc27-f615fb60a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "56c5dcc4-c399-469f-88fa-12789cc4c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn_1 = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.rnn_2 = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        h0, c0 = self.init_hidden(x1)\n",
    "        out1, (hn, cn) = self.rnn_1(x1, (h0, c0))\n",
    "        h0, c0 = self.init_hidden(x2)\n",
    "        out2, (hn, cn) = self.rnn_2(x2, (h0, c0))\n",
    "        out = torch.cat([out1[:, -1, :], out2[:, -1, :]], axis=1)\n",
    "        out = torch.sigmoid(self.fc(out))\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.to(\"cuda:0\") for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "cc804c24-0c06-4a22-bea0-933bd4c8ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "metric = BinaryF1Score().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "ebb5b2f5-8c10-4526-9293-56fb8810b96d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch:   1. Loss: 0.125941. Acc.: 85.90%. F1: 0.900224\n",
      "Epoch 1 best model saved with accuracy: 85.90%\n",
      "Epoch:   2. Loss: 0.270351. Acc.: 85.90%. F1: 0.899900\n",
      "Epoch:   3. Loss: 0.361747. Acc.: 86.20%. F1: 0.871252\n",
      "Epoch 3 best model saved with accuracy: 86.20%\n",
      "Epoch:   4. Loss: 0.186422. Acc.: 86.50%. F1: 0.888471\n",
      "Epoch 4 best model saved with accuracy: 86.50%\n",
      "Epoch:   5. Loss: 0.109723. Acc.: 86.20%. F1: 0.885560\n",
      "Epoch:   6. Loss: 0.206575. Acc.: 85.40%. F1: 0.874124\n",
      "Epoch:   7. Loss: 0.098551. Acc.: 86.30%. F1: 0.881045\n",
      "Epoch:   8. Loss: 0.192709. Acc.: 85.90%. F1: 0.896401\n",
      "Epoch:   9. Loss: 0.002972. Acc.: 85.90%. F1: 0.896780\n",
      "Epoch:  10. Loss: 0.159146. Acc.: 86.20%. F1: 0.872643\n",
      "Epoch:  11. Loss: 0.286916. Acc.: 85.90%. F1: 0.897032\n",
      "Epoch:  12. Loss: 0.083817. Acc.: 86.00%. F1: 0.873105\n",
      "Epoch:  13. Loss: 0.002491. Acc.: 85.10%. F1: 0.862581\n",
      "Epoch:  14. Loss: 0.096939. Acc.: 85.90%. F1: 0.900860\n",
      "Early stopping on epoch 14\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1    \n",
    "hidden_dim = 256\n",
    "layer_dim = 3\n",
    "output_dim = 1\n",
    "seq_dim = 72\n",
    "\n",
    "lr = 0.0001\n",
    "n_epochs = 1000\n",
    "iterations_per_epoch = len(train_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 10, 0\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.to(\"cuda:0\")#.cpu()#.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for i, (a_batch, l_batch, y_batch) in enumerate(train_dl):\n",
    "\n",
    "        model.train()\n",
    "        a_batch = a_batch.unsqueeze(2).to(\"cuda:0\")#.cpu()\n",
    "        l_batch = l_batch.unsqueeze(2).to(\"cuda:0\")#.cpu()#.cuda()\n",
    "        y_batch = y_batch.unsqueeze(1).to(\"cuda:0\")#.cpu()#.cuda()\n",
    "        sched.step()\n",
    "        opt.zero_grad()\n",
    "        out = model(a_batch, l_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    f1_tmp = []\n",
    "    for a_val, l_val, y_val in val_dl: #val_dl\n",
    "        a_val, l_val, y_val = [t.to(\"cuda:0\") for t in (a_val, l_val, y_val)]\n",
    "        out = model(a_val.unsqueeze(2), l_val.unsqueeze(2))\n",
    "        preds = out #F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        preds[preds < 0.5] = 0\n",
    "        preds[preds >= 0.5] = 1\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val.unsqueeze(1)).sum().item()\n",
    "        f1_tmp.append(metric(preds, y_val.unsqueeze(1)).item())\n",
    "    \n",
    "    f1 = sum(f1_tmp) / len(f1_tmp)\n",
    "    acc = correct / total\n",
    "\n",
    "    print(f'Epoch: {epoch:3d}. Loss: {loss.item():.6f}. Acc.: {acc:2.2%}. F1: {f1:.6f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'lstm_best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "2ccb0abf-5df8-4cc9-bf6b-364e225de2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_siam_v4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "81e621f1-5c51-429c-9ba2-c8540c524139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6318"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(targets) / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "5dfd9b9b-4ac6-48de-9a77-3308279982d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn_1 = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.rnn_2 = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        h0 = self.init_hidden(x1)\n",
    "        out1, hn = self.rnn_1(x1, h0)\n",
    "        h0 = self.init_hidden(x2)\n",
    "        out2, hn = self.rnn_2(x2, h0)\n",
    "        out = torch.cat([out1[:, -1, :], out2[:, -1, :]], axis=1)\n",
    "        out = torch.sigmoid(self.fc(out))\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return torch.stack([t.to(\"cuda:0\") for t in h0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "4da4726d-56f2-49e1-b0ba-51d430acf150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch:   1. Loss: 0.430290. Acc.: 87.20%. F1: 0.895476\n",
      "Epoch 1 best model saved with accuracy: 87.20%\n",
      "Epoch:   2. Loss: 0.451126. Acc.: 86.30%. F1: 0.875967\n",
      "Epoch:   3. Loss: 0.274705. Acc.: 85.50%. F1: 0.868307\n",
      "Epoch:   4. Loss: 0.187914. Acc.: 85.90%. F1: 0.896842\n",
      "Epoch:   5. Loss: 0.252547. Acc.: 85.90%. F1: 0.872287\n",
      "Epoch:   6. Loss: 0.272890. Acc.: 85.90%. F1: 0.901061\n",
      "Epoch:   7. Loss: 0.323231. Acc.: 85.90%. F1: 0.891283\n",
      "Epoch:   8. Loss: 0.332880. Acc.: 86.40%. F1: 0.887938\n",
      "Epoch:   9. Loss: 0.104859. Acc.: 85.70%. F1: 0.878138\n",
      "Epoch:  10. Loss: 0.299773. Acc.: 86.30%. F1: 0.870340\n",
      "Epoch:  11. Loss: 0.256945. Acc.: 85.90%. F1: 0.897588\n",
      "Early stopping on epoch 11\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1    \n",
    "hidden_dim = 256\n",
    "layer_dim = 3\n",
    "output_dim = 1\n",
    "seq_dim = 72\n",
    "\n",
    "lr = 0.0001\n",
    "n_epochs = 1000\n",
    "iterations_per_epoch = len(train_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 10, 0\n",
    "\n",
    "model = GRUClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.to(\"cuda:0\")#.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for i, (a_batch, l_batch, y_batch) in enumerate(train_dl):\n",
    "\n",
    "        model.train()\n",
    "        a_batch = a_batch.unsqueeze(2).to(\"cuda:0\")\n",
    "        l_batch = l_batch.unsqueeze(2).to(\"cuda:0\")#.cuda()\n",
    "        y_batch = y_batch.unsqueeze(1).to(\"cuda:0\")#.cuda()\n",
    "        sched.step()\n",
    "        opt.zero_grad()\n",
    "        out = model(a_batch, l_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    f1_tmp = []\n",
    "    for a_val, l_val, y_val in val_dl: #val_dl\n",
    "        a_val, l_val, y_val = [t.to(\"cuda:0\") for t in (a_val, l_val, y_val)]\n",
    "        out = model(a_val.unsqueeze(2), l_val.unsqueeze(2))\n",
    "        preds = out #F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        preds[preds < 0.5] = 0\n",
    "        preds[preds >= 0.5] = 1\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val.unsqueeze(1)).sum().item()\n",
    "        f1_tmp.append(metric(preds, y_val.unsqueeze(1)).item())\n",
    "    \n",
    "    f1 = sum(f1_tmp) / len(f1_tmp)\n",
    "    acc = correct / total\n",
    "\n",
    "    print(f'Epoch: {epoch:3d}. Loss: {loss.item():.6f}. Acc.: {acc:2.2%}. F1: {f1:.6f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'gru_siam.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "f7236f26-c814-4798-9fae-58e45619faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn_1 = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.rnn_2 = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        h0 = self.init_hidden(x1)\n",
    "        out1, hn = self.rnn_1(x1, h0)\n",
    "        h0 = self.init_hidden(x2)\n",
    "        out2, hn = self.rnn_2(x2, h0)\n",
    "        out = torch.cat([out1[:, -1, :], out2[:, -1, :]], axis=1)\n",
    "        out = torch.sigmoid(self.fc(out))\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return torch.stack([t.to(\"cuda:0\") for t in h0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "0ebf517b-4710-40f3-bf76-1a6bd18775cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch:   1. Loss: 0.409851. Acc.: 85.80%. F1: 0.879077\n",
      "Epoch 1 best model saved with accuracy: 85.80%\n",
      "Epoch:   2. Loss: 0.232657. Acc.: 84.70%. F1: 0.858451\n",
      "Epoch:   3. Loss: 0.919998. Acc.: 86.00%. F1: 0.865398\n",
      "Epoch 3 best model saved with accuracy: 86.00%\n",
      "Epoch:   4. Loss: 0.282409. Acc.: 86.10%. F1: 0.872080\n",
      "Epoch 4 best model saved with accuracy: 86.10%\n",
      "Epoch:   5. Loss: 0.179584. Acc.: 86.20%. F1: 0.867958\n",
      "Epoch 5 best model saved with accuracy: 86.20%\n",
      "Epoch:   6. Loss: 0.143323. Acc.: 86.10%. F1: 0.864766\n",
      "Epoch:   7. Loss: 0.090099. Acc.: 86.00%. F1: 0.864713\n",
      "Epoch:   8. Loss: 0.107419. Acc.: 86.10%. F1: 0.872636\n",
      "Epoch:   9. Loss: 0.310652. Acc.: 86.30%. F1: 0.862340\n",
      "Epoch 9 best model saved with accuracy: 86.30%\n",
      "Epoch:  10. Loss: 0.414545. Acc.: 86.30%. F1: 0.880339\n",
      "Epoch:  11. Loss: 0.280629. Acc.: 86.10%. F1: 0.870752\n",
      "Epoch:  12. Loss: 0.104920. Acc.: 85.70%. F1: 0.870960\n",
      "Epoch:  13. Loss: 0.281201. Acc.: 86.30%. F1: 0.875091\n",
      "Epoch:  14. Loss: 0.495537. Acc.: 86.30%. F1: 0.873848\n",
      "Epoch:  15. Loss: 0.298148. Acc.: 86.00%. F1: 0.872625\n",
      "Epoch:  16. Loss: 0.349948. Acc.: 85.50%. F1: 0.874411\n",
      "Epoch:  17. Loss: 0.079795. Acc.: 86.30%. F1: 0.867931\n",
      "Epoch:  18. Loss: 0.271355. Acc.: 86.30%. F1: 0.876213\n",
      "Epoch:  19. Loss: 0.267420. Acc.: 86.50%. F1: 0.880424\n",
      "Epoch 19 best model saved with accuracy: 86.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f504e45d940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/conda/envs/dragon/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 3811060, 3811172, 3811284, 3811396, 3811508, 3811620, 3811732) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/home/user/conda/envs/dragon/lib/python3.8/site-packages/torch/utils/data/dataloader.py:990\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/home/user/conda/envs/dragon/lib/python3.8/multiprocessing/queues.py:108\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[861], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m correct, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     38\u001b[0m f1_tmp \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a_val, l_val, y_val \u001b[38;5;129;01min\u001b[39;00m val_dl: \u001b[38;5;66;03m#val_dl\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     a_val, l_val, y_val \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m (a_val, l_val, y_val)]\n\u001b[1;32m     41\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(a_val\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m), l_val\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/home/user/conda/envs/dragon/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/user/conda/envs/dragon/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1186\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1186\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/user/conda/envs/dragon/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1152\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1154\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/user/conda/envs/dragon/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1003\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1002\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 3811060, 3811172, 3811284, 3811396, 3811508, 3811620, 3811732) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "input_dim = 1    \n",
    "hidden_dim = 256\n",
    "layer_dim = 3\n",
    "output_dim = 1\n",
    "seq_dim = 72\n",
    "\n",
    "lr = 0.0001\n",
    "n_epochs = 1000\n",
    "iterations_per_epoch = len(train_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 10, 0\n",
    "\n",
    "model = RNNClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.to(\"cuda:0\")#.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for i, (a_batch, l_batch, y_batch) in enumerate(train_dl):\n",
    "\n",
    "        model.train()\n",
    "        a_batch = a_batch.unsqueeze(2).to(\"cuda:0\")\n",
    "        l_batch = l_batch.unsqueeze(2).to(\"cuda:0\")#.cuda()\n",
    "        y_batch = y_batch.unsqueeze(1).to(\"cuda:0\")#.cuda()\n",
    "        sched.step()\n",
    "        opt.zero_grad()\n",
    "        out = model(a_batch, l_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    f1_tmp = []\n",
    "    for a_val, l_val, y_val in val_dl: #val_dl\n",
    "        a_val, l_val, y_val = [t.to(\"cuda:0\") for t in (a_val, l_val, y_val)]\n",
    "        out = model(a_val.unsqueeze(2), l_val.unsqueeze(2))\n",
    "        preds = out #F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        preds[preds < 0.5] = 0\n",
    "        preds[preds >= 0.5] = 1\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val.unsqueeze(1)).sum().item()\n",
    "        f1_tmp.append(metric(preds, y_val.unsqueeze(1)).item())\n",
    "    \n",
    "    f1 = sum(f1_tmp) / len(f1_tmp)\n",
    "    acc = correct / total\n",
    "\n",
    "    print(f'Epoch: {epoch:3d}. Loss: {loss.item():.6f}. Acc.: {acc:2.2%}. F1: {f1:.6f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'rnn_siam.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "30ce5038-fbcf-4b59-8146-136b3d541d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class UserStatisticItem:\n",
    "    sent_messages_count: int\n",
    "    received_messages_count: int \n",
    "    recipient_counts: int\n",
    "    bcc_count: int \n",
    "    cc_count: int \n",
    "    days_between_received_and_read: []\n",
    "    replied_messages_count: int \n",
    "    sent_characters_count: int \n",
    "    messages_outside_working_hours: int \n",
    "    received_to_sent_ratio: float\n",
    "    bytesReceivedToSentRatio: float\n",
    "    messages_with_question_and_no_reply: int\n",
    "    read_messages_later_than: int\n",
    "    count_events: int\n",
    "\n",
    "        \n",
    "\n",
    "    def dict(self):\n",
    "        return {k: v for k, v in asdict(self).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9514d4f3-ffa4-45ca-a990-eb8b8c3eb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "worker = pd.DataFrame(gen_worker_df(max_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7e132f74-b335-49e5-9005-ad249adf34a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3ccfd6d7-c3d8-4943-8352-59687d5bb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "form = []\n",
    "for r in worker.values:\n",
    "    form.append(UserStatisticItem(sent_messages_count=r[0],\n",
    "            received_messages_count=r[1], \n",
    "            recipient_counts=r[2],\n",
    "            bcc_count=r[3],\n",
    "            cc_count=r[4], \n",
    "            days_between_received_and_read= r[5],\n",
    "            replied_messages_count=r[6],\n",
    "            sent_characters_count=r[7], \n",
    "            messages_outside_working_hours=r[8], \n",
    "            received_to_sent_ratio=r[9],\n",
    "            bytesReceivedToSentRatio=r[10],\n",
    "            messages_with_question_and_no_reply=r[0],\n",
    "            read_messages_later_than=r[1],\n",
    "            count_events=r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6a24734e-f371-4344-8b3b-45efe18e5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_worker_format(form):\n",
    "    res = {}\n",
    "    for k in form[0].dict():\n",
    "        res[k] = []\n",
    "    for row in form:\n",
    "        row_d = row.dict()\n",
    "        for k in row_d:\n",
    "            res[k].append(row_d[k])\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c0046007-393c-4e2a-9e09-c17ff3248e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_messages_count</th>\n",
       "      <th>received_messages_count</th>\n",
       "      <th>recipient_counts</th>\n",
       "      <th>bcc_count</th>\n",
       "      <th>cc_count</th>\n",
       "      <th>days_between_received_and_read</th>\n",
       "      <th>replied_messages_count</th>\n",
       "      <th>sent_characters_count</th>\n",
       "      <th>messages_outside_working_hours</th>\n",
       "      <th>received_to_sent_ratio</th>\n",
       "      <th>bytesReceivedToSentRatio</th>\n",
       "      <th>messages_with_question_and_no_reply</th>\n",
       "      <th>read_messages_later_than</th>\n",
       "      <th>count_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1725</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1937</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1764</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1352</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>289</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>392</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>518</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>540</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_messages_count  received_messages_count  recipient_counts  bcc_count  \\\n",
       "0                     6                        3                 5          2   \n",
       "1                     7                        3                 5          2   \n",
       "2                     6                        4                 4          2   \n",
       "3                     6                        3                 4          2   \n",
       "4                     5                        2                 4          2   \n",
       "..                  ...                      ...               ...        ...   \n",
       "75                    4                        6                 5          0   \n",
       "76                    5                        5                 6          1   \n",
       "77                    5                        5                 5          0   \n",
       "78                    5                        8                 7          0   \n",
       "79                    5                        8                 7          0   \n",
       "\n",
       "    cc_count  days_between_received_and_read  replied_messages_count  \\\n",
       "0          5                               3                       2   \n",
       "1          6                               3                       2   \n",
       "2          6                               3                       2   \n",
       "3          5                               3                       2   \n",
       "4          4                               2                       2   \n",
       "..       ...                             ...                     ...   \n",
       "75         5                               1                       2   \n",
       "76         4                               1                       2   \n",
       "77         4                               2                       2   \n",
       "78         5                               2                       3   \n",
       "79         5                               2                       3   \n",
       "\n",
       "    sent_characters_count  messages_outside_working_hours  \\\n",
       "0                       5                            1725   \n",
       "1                       6                            2013   \n",
       "2                       6                            1937   \n",
       "3                       5                            1764   \n",
       "4                       4                            1352   \n",
       "..                    ...                             ...   \n",
       "75                      5                             167   \n",
       "76                      5                             289   \n",
       "77                      5                             392   \n",
       "78                      5                             518   \n",
       "79                      6                             540   \n",
       "\n",
       "    received_to_sent_ratio  bytesReceivedToSentRatio  \\\n",
       "0                        3                         2   \n",
       "1                        4                         2   \n",
       "2                        3                         2   \n",
       "3                        3                         2   \n",
       "4                        3                         2   \n",
       "..                     ...                       ...   \n",
       "75                       5                         0   \n",
       "76                       5                         0   \n",
       "77                       6                         0   \n",
       "78                       6                         0   \n",
       "79                       6                         0   \n",
       "\n",
       "    messages_with_question_and_no_reply  read_messages_later_than  \\\n",
       "0                                     6                         3   \n",
       "1                                     7                         3   \n",
       "2                                     6                         4   \n",
       "3                                     6                         3   \n",
       "4                                     5                         2   \n",
       "..                                  ...                       ...   \n",
       "75                                    4                         6   \n",
       "76                                    5                         5   \n",
       "77                                    5                         5   \n",
       "78                                    5                         8   \n",
       "79                                    5                         8   \n",
       "\n",
       "    count_events  \n",
       "0              5  \n",
       "1              5  \n",
       "2              4  \n",
       "3              4  \n",
       "4              4  \n",
       "..           ...  \n",
       "75             5  \n",
       "76             6  \n",
       "77             5  \n",
       "78             7  \n",
       "79             7  \n",
       "\n",
       "[80 rows x 14 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_worker_format(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "295e9a23-52ad-4840-a6f5-dea0f86de3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000],\n",
       "         [0.2000]]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale(a, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "5c18db3c-98d9-4255-946c-9b2e49183ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"lstm_siam_v4.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "1f628515-37f2-4d2f-a35e-0cf9865cd9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn_1): LSTM(1, 256, num_layers=3, batch_first=True)\n",
       "  (rnn_2): LSTM(1, 256, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "0abddef0-0b5f-4c5b-8ab0-e3355bc7dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(np.pad([7 for x in range(40)], (365 - 40 % 365, 0)))#.unsqueeze(0).unsqueeze(2)\n",
    "b = torch.tensor(np.pad([9 for x in range(20)], (365 - 20 % 365, 0)))#.unsqueeze(0).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "35f52ec6-6a23-482c-84b0-876fbcf1fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "         7, 7, 7, 7, 7]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9]))"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "91e55c1f-d720-408e-b7b2-3fc0b503dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = scale(a.unsqueeze(0).unsqueeze(2), 10)\n",
    "b = scale(b.unsqueeze(0).unsqueeze(2), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "21f27094-c142-46d0-ae0a-6591c0fef0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0025]], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - model(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "08d10a30-de86-464d-a075-41225629e005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent_messages_count': 6,\n",
       " 'received_messages_count': 3,\n",
       " 'recipient_counts': 5,\n",
       " 'bcc_count': 2,\n",
       " 'cc_count': 5,\n",
       " 'days_between_received_and_read': 3,\n",
       " 'replied_messages_count': 2,\n",
       " 'sent_characters_count': 5,\n",
       " 'messages_outside_working_hours': 1725,\n",
       " 'received_to_sent_ratio': 3,\n",
       " 'bytesReceivedToSentRatio': 2,\n",
       " 'messages_with_question_and_no_reply': 6,\n",
       " 'read_messages_later_than': 3,\n",
       " 'count_events': 5}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8555844-a1de-429c-942f-7b9e5da4fb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a248b74a-9c7b-4839-b743-5c323ffb767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proba is: 0.7206324149261821\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proba is: {predict_by_max(model, scale_by_max(worker, max_range), type_up)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f43dea31-1654-47d7-9786-308823aea466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn): LSTM(1, 256, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74930d-a562-455b-a587-0e09e58eb0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc1277-2fc4-4a16-8ba3-90f2d411390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dragon",
   "language": "python",
   "name": "dragon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
